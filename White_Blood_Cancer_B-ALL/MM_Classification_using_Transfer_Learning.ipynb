{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cancer Cells.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1l-8SrP-1-TphzlzSjKleYrKjDtIJENOP",
      "authorship_tag": "ABX9TyNBIRljEo1uqbydAwXeDl/0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RohitGanji/white-blood-cancer-all-mm/blob/main/White_Blood_Cancer_B-ALL/MM_Classification_using_Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9lvvV-g6IiR"
      },
      "source": [
        "# White Blood Cancer B-ALL/MM Classification using Transfer Learning\n",
        "\n",
        "You can download the dataset from [here](https://drive.google.com/drive/folders/18p96I52S1CyabBeAE8g5vcfhERh8ZJTi?usp=sharing)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRdGtVK6LTEv"
      },
      "source": [
        "## Creating Dataset from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccuo99-04gSA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba77bcdf-ba5a-44a5-b69c-eba45d44c0bc"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "train_dir = '/content/drive/MyDrive/Datasets/SN-AM-BALL-MM/training'\n",
        "test_dir = '/content/drive/MyDrive/Datasets/SN-AM-BALL-MM/testing'\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "train_data = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n",
        "                                                                 label_mode=\"binary\",\n",
        "                                                                 image_size=IMG_SIZE,\n",
        "                                                                 validation_split=0.2,\n",
        "                                                                 subset='training',\n",
        "                                                                 seed=1302)\n",
        "\n",
        "val_data = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n",
        "                                                                 label_mode=\"binary\",\n",
        "                                                                 image_size=IMG_SIZE,\n",
        "                                                                 validation_split=0.2,\n",
        "                                                                 subset='validation',\n",
        "                                                                 seed=1302)\n",
        "\n",
        "test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
        "                                                                 label_mode=\"binary\",\n",
        "                                                                 image_size=IMG_SIZE)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 173 files belonging to 2 classes.\n",
            "Using 139 files for training.\n",
            "Found 173 files belonging to 2 classes.\n",
            "Using 34 files for validation.\n",
            "Found 29 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gi8LotI-LZMI"
      },
      "source": [
        "## Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLI4lN62s3Lp"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Setup data augmentation\n",
        "data_augmentation = Sequential([\n",
        "  preprocessing.RandomFlip(\"horizontal\"),\n",
        "  preprocessing.RandomRotation(0.2),\n",
        "  preprocessing.RandomHeight(0.2),\n",
        "  preprocessing.RandomWidth(0.2),\n",
        "  preprocessing.RandomZoom(0.2),\n",
        "], name = \"data_augmentation\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UisLOgTbLdfw"
      },
      "source": [
        "## F1 Metric and Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GrGI-6Fj7gU"
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def f1_metric(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuiTzXfmrkYn"
      },
      "source": [
        "# Create checkpoint callback\n",
        "checkpoint_path = \"/content/model\"\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "                                                         save_weights_only=True,\n",
        "                                                         monitor=\"val_f1_metric\",\n",
        "                                                         save_best_only=True)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZ9XV2nyLi7A"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLR_t1dJkU6s"
      },
      "source": [
        "# Create a base model\n",
        "input_shape = (224, 224, 3)\n",
        "base_model = tf.keras.applications.EfficientNetB3(include_top=False)\n",
        "base_model.trainable = True\n",
        "\n",
        "for layer in base_model.layers[:-3]:\n",
        "  layer.trainable = False\n",
        "\n",
        "# Setup model architecture\n",
        "inputs = layers.Input(shape=(224,224,3), name=\"input_shape\")\n",
        "x = data_augmentation(inputs)\n",
        "x = base_model(x, training=False)\n",
        "x = layers.GlobalAveragePooling2D(name=\"GAP\")(x)\n",
        "x = layers.Dense(64, activation=\"relu\")(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\", name=\"output_layer\")(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\", f1_metric])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYfwbyaCnKi2",
        "outputId": "ea841857-7816-4e9b-8d47-3862c97f98d0"
      },
      "source": [
        "# Fit the model\n",
        "history = model.fit(train_data,\n",
        "                    epochs=30,\n",
        "                    steps_per_epoch=int(len(train_data)),\n",
        "                    validation_data=val_data,\n",
        "                    validation_steps=int(len(val_data)),\n",
        "                    callbacks=[checkpoint_callback])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "5/5 [==============================] - 24s 2s/step - loss: 0.5216 - accuracy: 0.7338 - f1_metric: 0.8161 - val_loss: 0.4001 - val_accuracy: 0.7647 - val_f1_metric: 0.8889\n",
            "Epoch 2/30\n",
            "5/5 [==============================] - 9s 804ms/step - loss: 0.0890 - accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.8489 - val_accuracy: 0.5588 - val_f1_metric: 0.6742\n",
            "Epoch 3/30\n",
            "5/5 [==============================] - 9s 781ms/step - loss: 0.0553 - accuracy: 0.9784 - f1_metric: 0.9838 - val_loss: 0.4455 - val_accuracy: 0.7941 - val_f1_metric: 0.9054\n",
            "Epoch 4/30\n",
            "5/5 [==============================] - 10s 1s/step - loss: 0.0275 - accuracy: 0.9856 - f1_metric: 0.9897 - val_loss: 0.2682 - val_accuracy: 0.9118 - val_f1_metric: 0.9545\n",
            "Epoch 5/30\n",
            "5/5 [==============================] - 9s 860ms/step - loss: 0.0170 - accuracy: 0.9928 - f1_metric: 0.9778 - val_loss: 0.4127 - val_accuracy: 0.8235 - val_f1_metric: 0.9118\n",
            "Epoch 6/30\n",
            "5/5 [==============================] - 10s 955ms/step - loss: 0.0019 - accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.2554 - val_accuracy: 0.9118 - val_f1_metric: 0.4571\n",
            "Epoch 7/30\n",
            "5/5 [==============================] - 10s 1s/step - loss: 0.0042 - accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.2838 - val_accuracy: 0.9118 - val_f1_metric: 0.9545\n",
            "Epoch 8/30\n",
            "5/5 [==============================] - 10s 1s/step - loss: 0.0031 - accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.3410 - val_accuracy: 0.9118 - val_f1_metric: 0.9545\n",
            "Epoch 9/30\n",
            "5/5 [==============================] - 9s 884ms/step - loss: 0.0021 - accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.3500 - val_accuracy: 0.9118 - val_f1_metric: 0.9516\n",
            "Epoch 10/30\n",
            "5/5 [==============================] - 10s 1s/step - loss: 0.0054 - accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.1840 - val_accuracy: 0.9118 - val_f1_metric: 0.9516\n",
            "Epoch 11/30\n",
            "5/5 [==============================] - 10s 1s/step - loss: 0.0011 - accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.1301 - val_accuracy: 0.9412 - val_f1_metric: 0.4706\n",
            "Epoch 12/30\n",
            "5/5 [==============================] - 9s 768ms/step - loss: 0.0020 - accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.1621 - val_accuracy: 0.9118 - val_f1_metric: 0.9545\n",
            "Epoch 13/30\n",
            "5/5 [==============================] - 9s 930ms/step - loss: 4.0741e-04 - accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.2557 - val_accuracy: 0.9118 - val_f1_metric: 0.8021\n",
            "Epoch 14/30\n",
            "5/5 [==============================] - 10s 935ms/step - loss: 2.3202e-04 - accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.3401 - val_accuracy: 0.8824 - val_f1_metric: 0.9375\n",
            "Epoch 15/30\n",
            "5/5 [==============================] - 10s 938ms/step - loss: 4.1914e-04 - accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.3668 - val_accuracy: 0.8529 - val_f1_metric: 0.9286\n",
            "Epoch 16/30\n",
            "5/5 [==============================] - 10s 911ms/step - loss: 2.6743e-04 - accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.3722 - val_accuracy: 0.8529 - val_f1_metric: 0.9286\n",
            "Epoch 17/30\n",
            "5/5 [==============================] - 10s 989ms/step - loss: 1.9279e-04 - accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.3638 - val_accuracy: 0.8529 - val_f1_metric: 0.9242\n",
            "Epoch 18/30\n",
            "5/5 [==============================] - 10s 1s/step - loss: 3.3989e-04 - accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.3443 - val_accuracy: 0.8824 - val_f1_metric: 0.9375\n",
            "Epoch 19/30\n",
            "5/5 [==============================] - 10s 945ms/step - loss: 6.1786e-04 - accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.2527 - val_accuracy: 0.8824 - val_f1_metric: 0.9412\n",
            "Epoch 20/30\n",
            "5/5 [==============================] - 10s 1s/step - loss: 6.0701e-04 - accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.1971 - val_accuracy: 0.9118 - val_f1_metric: 0.4571\n",
            "Epoch 21/30\n",
            "5/5 [==============================] - 9s 915ms/step - loss: 2.0923e-04 - accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.1662 - val_accuracy: 0.9118 - val_f1_metric: 0.4571\n",
            "Epoch 22/30\n",
            "5/5 [==============================] - 10s 1s/step - loss: 3.5204e-04 - accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.1814 - val_accuracy: 0.9118 - val_f1_metric: 0.9516\n",
            "Epoch 23/30\n",
            "5/5 [==============================] - 10s 1s/step - loss: 2.8839e-04 - accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.2285 - val_accuracy: 0.9118 - val_f1_metric: 0.9545\n",
            "Epoch 24/30\n",
            "5/5 [==============================] - 9s 1s/step - loss: 6.5578e-04 - accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.2994 - val_accuracy: 0.8824 - val_f1_metric: 0.9375\n",
            "Epoch 25/30\n",
            "5/5 [==============================] - 10s 860ms/step - loss: 1.1261e-04 - accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.2838 - val_accuracy: 0.9118 - val_f1_metric: 0.9516\n",
            "Epoch 26/30\n",
            "5/5 [==============================] - 9s 876ms/step - loss: 6.6178e-04 - accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.3234 - val_accuracy: 0.8824 - val_f1_metric: 0.9375\n",
            "Epoch 27/30\n",
            "5/5 [==============================] - 9s 721ms/step - loss: 8.3847e-04 - accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.2398 - val_accuracy: 0.9118 - val_f1_metric: 0.9545\n",
            "Epoch 28/30\n",
            "5/5 [==============================] - 9s 877ms/step - loss: 9.2644e-05 - accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.1831 - val_accuracy: 0.9118 - val_f1_metric: 0.9545\n",
            "Epoch 29/30\n",
            "5/5 [==============================] - 10s 1s/step - loss: 1.5117e-04 - accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.1684 - val_accuracy: 0.9118 - val_f1_metric: 0.9545\n",
            "Epoch 30/30\n",
            "5/5 [==============================] - 10s 1s/step - loss: 4.6499e-04 - accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.2216 - val_accuracy: 0.9118 - val_f1_metric: 0.9545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9U0oAapagGI",
        "outputId": "22a9c689-bd57-4632-901e-3be586fd0582"
      },
      "source": [
        "model.load_weights(\"/content/model\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fce29665290>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}