{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cancer Cells.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1l-8SrP-1-TphzlzSjKleYrKjDtIJENOP",
      "authorship_tag": "ABX9TyMcpKPGV1nR7umj6IZ0+uY4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RohitGanji/CNN-White_Blood_Cancer_Classification-ALL_MM/blob/main/White%20Blood%20Cancer%20Classification%20using%20Neural%20Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNcv02Ofj_tc",
        "outputId": "97e5ecd2-4d06-4c06-e33c-30ae088de0e4"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-c1cd7f27-00c8-2248-bd3f-a3e92a1956ba)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccuo99-04gSA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fec546b0-8d59-4d54-9cef-87de9d8673ef"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "train_dir = '/content/drive/MyDrive/Datasets/SN-AM-BALL-MM/training'\n",
        "test_dir = '/content/drive/MyDrive/Datasets/SN-AM-BALL-MM/testing'\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "train_data = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n",
        "                                                                 label_mode=\"binary\",\n",
        "                                                                 image_size=IMG_SIZE,\n",
        "                                                                 validation_split=0.2,\n",
        "                                                                 subset='training',\n",
        "                                                                 seed=1302)\n",
        "\n",
        "val_data = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n",
        "                                                                 label_mode=\"binary\",\n",
        "                                                                 image_size=IMG_SIZE,\n",
        "                                                                 validation_split=0.2,\n",
        "                                                                 subset='validation',\n",
        "                                                                 seed=1302)\n",
        "\n",
        "test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
        "                                                                 label_mode=\"binary\",\n",
        "                                                                 image_size=IMG_SIZE)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 173 files belonging to 2 classes.\n",
            "Using 139 files for training.\n",
            "Found 173 files belonging to 2 classes.\n",
            "Using 34 files for validation.\n",
            "Found 29 files belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLI4lN62s3Lp"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Setup data augmentation\n",
        "data_augmentation = Sequential([\n",
        "  preprocessing.RandomFlip(\"horizontal\"),\n",
        "  preprocessing.RandomRotation(0.2),\n",
        "  preprocessing.RandomHeight(0.2),\n",
        "  preprocessing.RandomWidth(0.2),\n",
        "  preprocessing.RandomZoom(0.2),\n",
        "], name = \"data_augmentation\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GrGI-6Fj7gU"
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def f1_metric(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuiTzXfmrkYn"
      },
      "source": [
        "# Create checkpoint callback\n",
        "checkpoint_path = \"/content/drive/MyDrive/Datasets/SN-AM-BALL-MM/checkpoint\"\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "                                                         save_weights_only=True,\n",
        "                                                         monitor=\"val_accuracy\",\n",
        "                                                         save_best_only=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLR_t1dJkU6s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d724e14a-4300-428c-e7ee-5d8fa54049b8"
      },
      "source": [
        "# Create a base model\n",
        "input_shape = (224, 224, 3)\n",
        "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
        "base_model.trainable = True\n",
        "\n",
        "for layer in base_model.layers[:-3]:\n",
        "  layer.trainable = False\n",
        "\n",
        "# Setup model architecture\n",
        "inputs = layers.Input(shape=(224,224,3), name=\"input_shape\")\n",
        "x = data_augmentation(inputs)\n",
        "x = base_model(x, training=False)\n",
        "x = layers.GlobalAveragePooling2D(name=\"GAP\")(x)\n",
        "x = layers.Dense(10, activation=\"relu\")(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\", name=\"output_layer\")(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\", f1_metric])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16711680/16705208 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYfwbyaCnKi2",
        "outputId": "e4c71b22-b280-4b50-bfa9-a5f9eaf01eb2"
      },
      "source": [
        "# Fit the model\n",
        "history = model.fit(train_data,\n",
        "                    epochs=8,\n",
        "                    validation_data=val_data,\n",
        "                    validation_steps=int(len(val_data)),\n",
        "                    callbacks=[checkpoint_callback])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "5/5 [==============================] - 126s 5s/step - loss: 0.4505 - accuracy: 0.8777 - f1_metric: 0.9007 - val_loss: 0.3169 - val_accuracy: 0.8529 - val_f1_metric: 0.4444\n",
            "Epoch 2/8\n",
            "5/5 [==============================] - 54s 623ms/step - loss: 0.1014 - accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.5263 - val_accuracy: 0.6471 - val_f1_metric: 0.6992\n",
            "Epoch 3/8\n",
            "5/5 [==============================] - 7s 613ms/step - loss: 0.0175 - accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.2196 - val_accuracy: 0.9118 - val_f1_metric: 0.4706\n",
            "Epoch 4/8\n",
            "5/5 [==============================] - 7s 730ms/step - loss: 0.0085 - accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.2006 - val_accuracy: 0.9412 - val_f1_metric: 0.9687\n",
            "Epoch 5/8\n",
            "5/5 [==============================] - 8s 765ms/step - loss: 0.0062 - accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.3876 - val_accuracy: 0.9118 - val_f1_metric: 0.4571\n",
            "Epoch 6/8\n",
            "5/5 [==============================] - 7s 613ms/step - loss: 0.0022 - accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.3241 - val_accuracy: 0.9118 - val_f1_metric: 0.4571\n",
            "Epoch 7/8\n",
            "5/5 [==============================] - 7s 572ms/step - loss: 8.4716e-04 - accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.2770 - val_accuracy: 0.9412 - val_f1_metric: 0.4706\n",
            "Epoch 8/8\n",
            "5/5 [==============================] - 7s 632ms/step - loss: 7.1981e-04 - accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.3131 - val_accuracy: 0.9118 - val_f1_metric: 0.9545\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHEXMOMUac75",
        "outputId": "575b0193-62bc-45ee-fb71-a97f64bfbe93"
      },
      "source": [
        "model.evaluate(val_data)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 1s 18ms/step - loss: 0.3131 - accuracy: 0.9118 - f1_metric: 0.8021\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3131120204925537, 0.9117646813392639, 0.8020832538604736]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9U0oAapagGI",
        "outputId": "f2ce3a8c-01e9-4cf7-da93-2a6369a11e82"
      },
      "source": [
        "model.load_weights('/content/drive/MyDrive/Datasets/SN-AM-BALL-MM/checkpoint')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fbc8a649290>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgyEHz79jH4s",
        "outputId": "68f4945f-f369-40fc-90a6-f2c94c18661e"
      },
      "source": [
        "model.evaluate(test_data)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 14s 14s/step - loss: 0.1629 - accuracy: 0.8966 - f1_metric: 0.9032\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.16292905807495117, 0.8965517282485962, 0.9032257199287415]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    }
  ]
}